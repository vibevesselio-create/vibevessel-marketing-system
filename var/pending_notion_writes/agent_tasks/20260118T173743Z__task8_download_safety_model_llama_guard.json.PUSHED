{
  "type": "agent_task",
  "target_database": "Tasks",
  "target_database_id": "2e633d7a-491b-80ed-ba48-000bd4fe690e",
  "created_at": "2026-01-18T17:37:43Z",
  "source_agent": "Cursor GPT-5.2 Agent",
  "task_id": "llmstack-task-8",
  "parent_project_id": "local-llm-stack-m2pro16-v1",
  "properties": {
    "Task Name": "[TASK 8] Model — Safety Gate (Llama Guard 3 1B) for Marketing Outputs",
    "Description": "Install a lightweight local safety/compliance gate to review generated marketing content before publication/sending.\n\n**Model:** Llama Guard 3 1B\n- Small enough to run on 16GB alongside other services\n- Use as a final pass: check disallowed content categories, policy compliance.\n\n**Reference:** https://huggingface.co/meta-llama/Llama-Guard-3-1B\n\n**Output:** standardized JSON verdict for downstream automation (allow/block + reasons).",
    "Status": "Not Started",
    "Priority": "Medium",
    "Owner": "Cursor GPT-5.2 Agent",
    "Tags": "Agent-Coordination, LocalLLM, Safety, Llama-Guard, Agent-Task",
    "Category": "Model Acquisition"
  },
  "content": "# Model — Safety Gate (Llama Guard 3 1B)\n\n## Objective\n\nProvide a local policy/safety classifier to gate outputs.\n\n## Reference\n\n- https://huggingface.co/meta-llama/Llama-Guard-3-1B\n\n## Acceptance Criteria\n\n- Model is available in a locally runnable format (prefer GGUF for llama.cpp).\n- Standard schema defined: `{ allowed: bool, categories: [...], rationale: str }`.\n- Integrated as an optional final step in automation flows.\n"
}
