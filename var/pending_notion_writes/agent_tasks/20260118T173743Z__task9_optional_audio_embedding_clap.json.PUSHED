{
  "type": "agent_task",
  "target_database": "Tasks",
  "target_database_id": "2e633d7a-491b-80ed-ba48-000bd4fe690e",
  "created_at": "2026-01-18T17:37:43Z",
  "source_agent": "Cursor GPT-5.2 Agent",
  "task_id": "llmstack-task-9",
  "parent_project_id": "local-llm-stack-m2pro16-v1",
  "properties": {
    "Task Name": "[TASK 9] Optional Model — Audio Similarity/Tagging (CLAP Audio↔Text Embeddings)",
    "Description": "Optional: add CLAP to support audio labeling and similarity search (\"find tracks that sound like X\", \"tag audio bed as cinematic/ambient\", etc.).\n\n**Reference:**\n- CLAP repo: https://github.com/LAION-AI/CLAP\n- Transformers CLAP docs: https://huggingface.co/docs/transformers/main/en/model_doc/clap\n\n**Value for marketing:**\n- Auto-tag music beds and SFX libraries\n- Search audio assets by text descriptions\n\n**Note:** parameter counts vary by checkpoint; treat as optional due to added operational surface area.",
    "Status": "Not Started",
    "Priority": "Low",
    "Owner": "Cursor GPT-5.2 Agent",
    "Tags": "Agent-Coordination, LocalLLM, Audio, CLAP, Embeddings, Agent-Task",
    "Category": "Model Acquisition"
  },
  "content": "# Optional Model — CLAP Audio↔Text Embeddings\n\n## Objective\n\nEnable audio similarity and text-based audio search.\n\n## References\n\n- https://github.com/LAION-AI/CLAP\n- https://huggingface.co/docs/transformers/main/en/model_doc/clap\n\n## Acceptance Criteria\n\n- A chosen CLAP checkpoint is documented and cached under `$SEREN_LLM_ROOT/hf`.\n- A minimal CLI/script exists to compute audio embeddings and query by text.\n"
}
